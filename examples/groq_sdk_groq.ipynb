{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92719f13ce48b2c4",
   "metadata": {},
   "source": [
    "# How to track Groq request in PromptSail \n",
    "\n",
    "\n",
    "In this example we will use the official python groq packg. \n",
    "\n",
    "1. Install all the necessary packages from [examples/pyproject.toml](pyproject.toml) by running the following command:\n",
    "    ```bash \n",
    "    cd prompt_sail/examples\n",
    "    poetry install\n",
    "    ```\n",
    "1. Add you API key into ```examples/.env``` file as ```GROQ_API_KEY```, you can generate it [here](https://console.groq.com/keys)\n",
    "1. Setup project and AI provider in Prompt Sail dashboard, \n",
    "    * Go to demo page [Try PromptSail](https://try-promptsail.azurewebsites.net/) and create a new project or use an existing one.\n",
    "    * [Run the PromptSail docker images](https://promptsail.com/docs/quick-start-guide/#pull-and-run-the-docker-images-from-ghcr) and go to UI at http://localhost/.\n",
    "    * Create new project title 'models playground' with slug `project_slug` (or choose other existing one).\n",
    "    * Add Groq AI provider to your PromptSail project. Provider structure should look like this one:\n",
    "    ```json\n",
    "        {\n",
    "            deployment_name: 'Groq',\n",
    "            slug: 'groq',\n",
    "            api_base: 'https://api.groq.com',\n",
    "            description: '',\n",
    "            provider_name: 'Groq'\n",
    "        }\n",
    "    ```\n",
    "1. Now using project slug and provider slug you can get access to your models \n",
    "    * using try promptsail: ```https://try-promptsail.azurewebsites.net/api/models-playground/groq/```\n",
    "    * using local deployment: ```http://localhost:8000/models-playground/groq/```\n",
    "1. Now you can send your request to ```http://localhost:8000/models-playground/groq/``` where ```models-playground``` is your project's slug and ```groq``` is the provider's slug.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T09:51:43.565327Z",
     "start_time": "2024-07-11T09:51:43.553954Z"
    }
   },
   "source": [
    "from groq import Groq\n",
    "from dotenv import dotenv_values\n",
    "from rich import print\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "api_key = config[\"GROQ_API_KEY\"]\n",
    "\n",
    "endpoint = \"http://localhost:8000/models-playground/groq\"\n",
    "# endpoint = \"https://try-promptsail.azurewebsites.net/api/models-playground/groq/\""
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b608c2c8b75a3d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:51:50.118938Z",
     "start_time": "2024-07-11T09:51:46.990411Z"
    }
   },
   "source": [
    "client = Groq(\n",
    "    api_key=api_key,\n",
    "    base_url=endpoint\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fast language models have become increasingly important in recent years due to the rapid growth and evolution of \n",
       "natural language processing \u001B[1m(\u001B[0mNLP\u001B[1m)\u001B[0m and artificial intelligence \u001B[1m(\u001B[0mAI\u001B[1m)\u001B[0m. Here are some reasons why fast language models \n",
       "are crucial:\n",
       "\n",
       "\u001B[1;36m1\u001B[0m. **Speed and Efficiency**: Fast language models enable real-time processing of vast amounts of text data, making \n",
       "them essential for applications that require instant responses, such as chatbots, virtual assistants, and online \n",
       "search engines. They can process and generate text at incredible speeds, outpacing traditional language models.\n",
       "\u001B[1;36m2\u001B[0m. **Scalability**: As the amount of data grows exponentially, fast language models can handle larger datasets and \n",
       "more complex tasks, such as sentiment analysis, text classification, and language translation. This scalability \n",
       "enables them to support a broader range of applications and users.\n",
       "\u001B[1;36m3\u001B[0m. **Improved Task Completion**: Fast language models can perform tasks more efficiently, reducing computational \n",
       "costs and enabling them to focus on more complex or nuanced tasks. This improved performance can lead to better \n",
       "results in areas like text summarization, named entity recognition, and question answering.\n",
       "\u001B[1;36m4\u001B[0m. **Enhanced User Experience**: Fast language models can provide faster and more accurate responses, enhancing the\n",
       "overall user experience in applications like search engines, customer service chatbots, and language translation \n",
       "tools. This can lead to increased user satisfaction, loyalty, and engagement.\n",
       "\u001B[1;36m5\u001B[0m. **Real-time Applications**: Fast language models are particularly useful in real-time applications like live \n",
       "transcription, speech-to-text systems, and language translation in video conferencing. They can provide \n",
       "instantaneous translations, enabling seamless communication across language barriers.\n",
       "\u001B[1;36m6\u001B[0m. **Big Data Processing**: Fast language models can handle the sheer volume of data generated by social media, \n",
       "online forums, and other sources. They can analyze large datasets in real-time, providing insights and patterns \n",
       "that might otherwise go unnoticed.\n",
       "\u001B[1;36m7\u001B[0m. **Data Streaming**: Fast language models can process data streams in real-time, enabling applications like \n",
       "monitoring social media trends, detecting spoilers in movie reviews, or analyzing customer feedback.\n",
       "\u001B[1;36m8\u001B[0m. **Edge Computing**: With the increasing adoption of edge computing, fast language models can be deployed on \n",
       "devices at the edge, reducing latency and improving responsiveness. This is particularly important for applications\n",
       "that require low-latency processing, such as autonomous vehicles or smart home devices.\n",
       "\u001B[1;36m9\u001B[0m. **Increased Flexibility**: Fast language models can be fine-tuned for specific tasks or domains, allowing them \n",
       "to adapt to diverse use cases and domains. This flexibility makes them versatile tools for a wide range of \n",
       "applications.\n",
       "\u001B[1;36m10\u001B[0m. **Future Research and Development**: The advancements in fast language models enable researchers to explore new\n",
       "areas, such as multimodal processing, cross-lingual understanding, and human-machine interfaces. These \n",
       "breakthroughs can lead to significant innovations in AI, NLP, and other fields.\n",
       "\n",
       "In summary, fast language models play a crucial role in enabling rapid, efficient, and accurate processing of large\n",
       "amounts of text data. Their importance extends to various areas, including real-time applications, big data \n",
       "processing, edge computing, and future research and development.\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fast language models have become increasingly important in recent years due to the rapid growth and evolution of \n",
       "natural language processing <span style=\"font-weight: bold\">(</span>NLP<span style=\"font-weight: bold\">)</span> and artificial intelligence <span style=\"font-weight: bold\">(</span>AI<span style=\"font-weight: bold\">)</span>. Here are some reasons why fast language models \n",
       "are crucial:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Speed and Efficiency**: Fast language models enable real-time processing of vast amounts of text data, making \n",
       "them essential for applications that require instant responses, such as chatbots, virtual assistants, and online \n",
       "search engines. They can process and generate text at incredible speeds, outpacing traditional language models.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Scalability**: As the amount of data grows exponentially, fast language models can handle larger datasets and \n",
       "more complex tasks, such as sentiment analysis, text classification, and language translation. This scalability \n",
       "enables them to support a broader range of applications and users.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Improved Task Completion**: Fast language models can perform tasks more efficiently, reducing computational \n",
       "costs and enabling them to focus on more complex or nuanced tasks. This improved performance can lead to better \n",
       "results in areas like text summarization, named entity recognition, and question answering.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Enhanced User Experience**: Fast language models can provide faster and more accurate responses, enhancing the\n",
       "overall user experience in applications like search engines, customer service chatbots, and language translation \n",
       "tools. This can lead to increased user satisfaction, loyalty, and engagement.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. **Real-time Applications**: Fast language models are particularly useful in real-time applications like live \n",
       "transcription, speech-to-text systems, and language translation in video conferencing. They can provide \n",
       "instantaneous translations, enabling seamless communication across language barriers.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>. **Big Data Processing**: Fast language models can handle the sheer volume of data generated by social media, \n",
       "online forums, and other sources. They can analyze large datasets in real-time, providing insights and patterns \n",
       "that might otherwise go unnoticed.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>. **Data Streaming**: Fast language models can process data streams in real-time, enabling applications like \n",
       "monitoring social media trends, detecting spoilers in movie reviews, or analyzing customer feedback.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>. **Edge Computing**: With the increasing adoption of edge computing, fast language models can be deployed on \n",
       "devices at the edge, reducing latency and improving responsiveness. This is particularly important for applications\n",
       "that require low-latency processing, such as autonomous vehicles or smart home devices.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>. **Increased Flexibility**: Fast language models can be fine-tuned for specific tasks or domains, allowing them \n",
       "to adapt to diverse use cases and domains. This flexibility makes them versatile tools for a wide range of \n",
       "applications.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>. **Future Research and Development**: The advancements in fast language models enable researchers to explore new\n",
       "areas, such as multimodal processing, cross-lingual understanding, and human-machine interfaces. These \n",
       "breakthroughs can lead to significant innovations in AI, NLP, and other fields.\n",
       "\n",
       "In summary, fast language models play a crucial role in enabling rapid, efficient, and accurate processing of large\n",
       "amounts of text data. Their importance extends to various areas, including real-time applications, big data \n",
       "processing, edge computing, and future research and development.\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024ddefac0450fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
