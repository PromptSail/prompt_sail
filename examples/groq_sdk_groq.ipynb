{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# How to request to Groq using PromptSail proxy\n",
    "1. First of all install groq package ```pip install groq```\n",
    "2. Add you API key into ```.env``` file as ```GROQ_API_KEY```, you can generate it [here](https://console.groq.com/keys)\n",
    "3. Add Groq provider to your PromptSail project. Provider structure should look like this one:\n",
    "```json\n",
    "    {\n",
    "        deployment_name: 'Groq',\n",
    "        slug: 'groq',\n",
    "        api_base: 'https://api.groq.com',\n",
    "        description: '',\n",
    "        provider_name: 'Groq'\n",
    "    }\n",
    "```\n",
    "4. Now you can send your request to ```http://localhost:8000/models-playground/groq``` where ```models-playground``` is your project's slug and ```groq``` is the provider's slug."
   ],
   "id": "92719f13ce48b2c4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:07:47.881907Z",
     "start_time": "2024-07-02T09:07:47.870396Z"
    }
   },
   "source": [
    "from groq import Groq\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "api_key = config[\"GROQ_API_KEY\"]\n",
    "\n",
    "endpoint = 'http://localhost:8000/models-playground/groq'\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:07:51.388077Z",
     "start_time": "2024-07-02T09:07:48.573431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "client = Groq(\n",
    "    api_key=api_key,\n",
    "    base_url=endpoint\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ],
   "id": "b608c2c8b75a3d42",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fast language models, also known as efficient language models or compact language models, have gained significant importance in recent years due to their ability to process and generate text quickly and efficiently. Here are some reasons why fast language models are crucial:\n",
      "\n",
      "1. **Real-time Processing**: Fast language models enable real-time processing of large volumes of text data, making them essential for applications that require immediate responses, such as chatbots, virtual assistants, and language translation.\n",
      "2. **Scalability**: With the increasing amount of text data being generated every day, fast language models can handle large datasets, reducing the processing time and computational overhead.\n",
      "3. **Improved User Experience**: Fast language models enable chatbots and other language-based interfaces to respond quickly to user queries, providing a seamless and responsive experience.\n",
      "4. **Enhanced Responsiveness**: Fast language models can quickly generate text responses to user inputs, making them ideal for applications that require rapid responses, such as customer service, sentiment analysis, and text classification.\n",
      "5. **Cost-Effective**: Fast language models require less computational resources and memory compared to traditional language models, making them a cost-effective solution for organizations.\n",
      "6. **Applications in NLP**: Fast language models have numerous applications in Natural Language Processing (NLP), including:\n",
      "\t* Sentiment Analysis: Fast language models can quickly analyze text to identify sentiments, emotions, and opinions.\n",
      "\t* Text Classification: Fast language models can categorize text into specific categories, such as spam vs. non-spam emails.\n",
      "\t* Language Translation: Fast language models can quickly translate text from one language to another.\n",
      "\t* Summarization: Fast language models can summarize long pieces of text, highlighting the most important information.\n",
      "7. **Advancements in AI**: Fast language models are essential for the development of Artificial Intelligence (AI) and Machine Learning (ML) applications, enabling faster and more accurate processing of text data.\n",
      "8. **Improved Search Engine Rankings**: Fast language models can quickly index and rank text data, improving search engine rankings and user experience.\n",
      "9. **Content Generation**: Fast language models can generate high-quality content quickly, making them ideal for applications such as content creation, blog posts, and product descriptions.\n",
      "10. **Competitive Advantage**: Organizations that integrate fast language models into their applications can gain a competitive advantage by offering faster and more responsive language-based services, enhancing their overall customer experience.\n",
      "\n",
      "In summary, fast language models are crucial due to their ability to process and generate text quickly and efficiently, making them essential for applications that require real-time processing, scalability, and improved user experience.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5024ddefac0450fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
