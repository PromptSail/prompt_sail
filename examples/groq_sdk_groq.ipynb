{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92719f13ce48b2c4",
   "metadata": {},
   "source": [
    "# How to track Groq request in PromptSail \n",
    "\n",
    "\n",
    "In this example we will use the official python groq packg. \n",
    "\n",
    "1. Install all the necessary packages from [examples/pyproject.toml](pyproject.toml) by running the following command:\n",
    "    ```bash \n",
    "    cd prompt_sail/examples\n",
    "    poetry install\n",
    "    ```\n",
    "1. Add you API key into ```examples/.env``` file as ```GROQ_API_KEY```, you can generate it [here](https://console.groq.com/keys)\n",
    "1. Setup project and AI provider in Prompt Sail dashboard, \n",
    "    * Go to demo page [Try PromptSail](https://try-promptsail.azurewebsites.net/) and create a new project or use an existing one.\n",
    "    * [Run the PromptSail docker images](https://promptsail.com/docs/quick-start-guide/#pull-and-run-the-docker-images-from-ghcr) and go to UI at http://localhost/.\n",
    "    * Create new project title 'models playground' with slug `project_slug` (or choose other existing one).\n",
    "    * Add Groq AI provider to your PromptSail project. Provider structure should look like this one:\n",
    "    ```json\n",
    "        {\n",
    "            deployment_name: 'Groq',\n",
    "            slug: 'groq',\n",
    "            api_base: 'https://api.groq.com',\n",
    "            description: '',\n",
    "            provider_name: 'Groq'\n",
    "        }\n",
    "    ```\n",
    "1. Now using project slug and provider slug you can get access to your models \n",
    "    * using try promptsail: ```https://try-promptsail.azurewebsites.net/api/models-playground/groq/```\n",
    "    * using local deployment: ```http://localhost:8000/models-playground/ollama/```\n",
    "1. Now you can send your request to ```http://localhost:8000/models-playground/groq/``` where ```models-playground``` is your project's slug and ```groq``` is the provider's slug.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:07:47.881907Z",
     "start_time": "2024-07-02T09:07:47.870396Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from dotenv import dotenv_values\n",
    "from rich import print\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "api_key = config[\"GROQ_API_KEY\"]\n",
    "\n",
    "#endpoint = \"http://localhost:8000/models-playground/groq\"\n",
    "endpoint = \"https://try-promptsail.azurewebsites.net/api/models-playground/groq/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b608c2c8b75a3d42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-02T09:07:51.388077Z",
     "start_time": "2024-07-02T09:07:48.573431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Fast language models, also known as accelerated or sped-up language models, have gained significant attention in \n",
       "the field of natural language processing <span style=\"font-weight: bold\">(</span>NLP<span style=\"font-weight: bold\">)</span> in recent years. These models are designed to process and generate \n",
       "text quickly, accurately, and efficiently, making them crucial for various applications. Here are some reasons why \n",
       "fast language models are important:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Real-time processing**: With the increasing demand for instant responses, fast language models enable \n",
       "real-time processing of text data. This is particularly important in applications like chatbots, virtual \n",
       "assistants, and customer service platforms, where quick responses are essential.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Handling large volumes of data**: Fast language models can handle massive amounts of data quickly, making them\n",
       "ideal for applications like text classification, sentiment analysis, and language translation. This ability to \n",
       "process large volumes of data enables organizations to make data-driven decisions faster.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Improved user experience**: Fast language models can provide fast and accurate responses to users, improving \n",
       "their overall experience. For instance, in a search engine or recommendation system, a quick response from a fast \n",
       "language model can enhance the user's satisfaction and engagement.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>. **Enhanced performance in edge computing**: Fast language models are designed to work efficiently on edge \n",
       "devices, such as smartphones, tablets, and IoT devices. This makes them ideal for applications that require \n",
       "low-latency processing and minimal data transmission.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. **Increased efficiency in computing resources**: Fast language models are optimized to use fewer computational \n",
       "resources, making them more feasible for deploying on low-power devices or in situations where resources are \n",
       "limited.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>. **Better performance on cloud-based services**: Fast language models can take advantage of cloud-based services \n",
       "like AWS, Google Cloud, or Azure, which provide scalable computing resources. This enables organizations to process\n",
       "large volumes of data quickly and efficiently.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>. **Advancements in NLP research**: Fast language models have pushed the boundaries of NLP research, enabling \n",
       "scientists to explore new areas, such as multimodal processing, natural language understanding, and language \n",
       "generation.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>. **Improved accuracy and robustness**: Fast language models often incorporate advanced techniques, such as \n",
       "knowledge distillation, adversarial training, and pre-training, which can improve their accuracy and robustness in \n",
       "handling out-of-vocabulary words, misspellings, and noisy data.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>. **Increased applicability across industries**: Fast language models have the potential to transform various \n",
       "industries, including customer service, healthcare, finance, education, and entertainment, by providing fast and \n",
       "accurate text processing capabilities.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>. **Competitive advantage**: Organizations that adopt fast language models can gain a competitive advantage by \n",
       "providing faster and more accurate text processing capabilities, which can lead to improved customer satisfaction \n",
       "and loyalty.\n",
       "\n",
       "In summary, fast language models are crucial for organizations seeking to improve their text processing \n",
       "capabilities, enhance user experience, and stay competitive in today's fast-paced digital landscape.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Fast language models, also known as accelerated or sped-up language models, have gained significant attention in \n",
       "the field of natural language processing \u001B[1m(\u001B[0mNLP\u001B[1m)\u001B[0m in recent years. These models are designed to process and generate \n",
       "text quickly, accurately, and efficiently, making them crucial for various applications. Here are some reasons why \n",
       "fast language models are important:\n",
       "\n",
       "\u001B[1;36m1\u001B[0m. **Real-time processing**: With the increasing demand for instant responses, fast language models enable \n",
       "real-time processing of text data. This is particularly important in applications like chatbots, virtual \n",
       "assistants, and customer service platforms, where quick responses are essential.\n",
       "\u001B[1;36m2\u001B[0m. **Handling large volumes of data**: Fast language models can handle massive amounts of data quickly, making them\n",
       "ideal for applications like text classification, sentiment analysis, and language translation. This ability to \n",
       "process large volumes of data enables organizations to make data-driven decisions faster.\n",
       "\u001B[1;36m3\u001B[0m. **Improved user experience**: Fast language models can provide fast and accurate responses to users, improving \n",
       "their overall experience. For instance, in a search engine or recommendation system, a quick response from a fast \n",
       "language model can enhance the user's satisfaction and engagement.\n",
       "\u001B[1;36m4\u001B[0m. **Enhanced performance in edge computing**: Fast language models are designed to work efficiently on edge \n",
       "devices, such as smartphones, tablets, and IoT devices. This makes them ideal for applications that require \n",
       "low-latency processing and minimal data transmission.\n",
       "\u001B[1;36m5\u001B[0m. **Increased efficiency in computing resources**: Fast language models are optimized to use fewer computational \n",
       "resources, making them more feasible for deploying on low-power devices or in situations where resources are \n",
       "limited.\n",
       "\u001B[1;36m6\u001B[0m. **Better performance on cloud-based services**: Fast language models can take advantage of cloud-based services \n",
       "like AWS, Google Cloud, or Azure, which provide scalable computing resources. This enables organizations to process\n",
       "large volumes of data quickly and efficiently.\n",
       "\u001B[1;36m7\u001B[0m. **Advancements in NLP research**: Fast language models have pushed the boundaries of NLP research, enabling \n",
       "scientists to explore new areas, such as multimodal processing, natural language understanding, and language \n",
       "generation.\n",
       "\u001B[1;36m8\u001B[0m. **Improved accuracy and robustness**: Fast language models often incorporate advanced techniques, such as \n",
       "knowledge distillation, adversarial training, and pre-training, which can improve their accuracy and robustness in \n",
       "handling out-of-vocabulary words, misspellings, and noisy data.\n",
       "\u001B[1;36m9\u001B[0m. **Increased applicability across industries**: Fast language models have the potential to transform various \n",
       "industries, including customer service, healthcare, finance, education, and entertainment, by providing fast and \n",
       "accurate text processing capabilities.\n",
       "\u001B[1;36m10\u001B[0m. **Competitive advantage**: Organizations that adopt fast language models can gain a competitive advantage by \n",
       "providing faster and more accurate text processing capabilities, which can lead to improved customer satisfaction \n",
       "and loyalty.\n",
       "\n",
       "In summary, fast language models are crucial for organizations seeking to improve their text processing \n",
       "capabilities, enhance user experience, and stay competitive in today's fast-paced digital landscape.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client = Groq(\n",
    "    api_key=api_key,\n",
    "    base_url=endpoint\n",
    ")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-8b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024ddefac0450fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
