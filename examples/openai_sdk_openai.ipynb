{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to connect to OpenAI service via PromptSail and OpenAI Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the OpenAI Python SDK and load your API key from the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI api key=sk-...Uzy\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from pprint import pprint\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "openai_key = config[\"OPENAI_API_KEY\"]\n",
    "openai_org_id = config[\"OPENAI_ORG_ID\"]\n",
    "print(\n",
    "    f\"OpenAI api key={openai_key[0:3]}...{openai_key[-3:]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see what gpt models are available for the API key we loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
      " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
      " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
      " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
      " Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
      " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
      " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
      " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
      " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
      " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
      " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
      " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
      " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
      " Model(id='gpt-4-1106-vision-preview', created=1711473033, object='model', owned_by='system'),\n",
      " Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'),\n",
      " Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'),\n",
      " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
      " Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system')]\n"
     ]
    }
   ],
   "source": [
    "client_org = OpenAI(\n",
    "    organization=openai_org_id,\n",
    "    api_key=openai_key,\n",
    ")\n",
    "models = client_org.models.list().data\n",
    "models = [m for m in models if \"gpt\" in m.id.lower()]\n",
    "\n",
    "# sort models by model id\n",
    "models = sorted(models, key=lambda x: x.id)\n",
    "\n",
    "# print models which contains gpt in the name\n",
    "pprint(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the direct connection to OpenAI service via OpenAI Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "haiku_prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Compose a haiku that explains the concept of recursion in programming.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "poem_prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Compose a five line poem that explains the concept of recursion in programming.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "yoda_prompt = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"Yoda assistant you are, skilled in explaining complex life and phisopical matters.\",\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What number 42 means, be brief.\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('In the realm of code, a loop is spun,\\n'\n",
      " 'But recursion dances to a different drum,\\n'\n",
      " 'A function calls itself, a tale retold,\\n'\n",
      " 'Until the base case breaks the mold,\\n'\n",
      " 'Infinite depth, a labyrinth to unfold.')\n"
     ]
    }
   ],
   "source": [
    "oai_client = OpenAI(api_key=openai_key)\n",
    "\n",
    "response = oai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=poem_prompt,\n",
    ")\n",
    "\n",
    "pprint(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the streaming API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In\n",
      " code\n",
      "'s\n",
      " graceful\n",
      " dance\n",
      ",\n",
      "\n",
      "Functions\n",
      " call\n",
      " themselves\n",
      " with\n",
      " grace\n",
      ",\n",
      "\n",
      "Rec\n",
      "ursion\n",
      "'s\n",
      " embrace\n",
      ".\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "oai_client = OpenAI(api_key=openai_key)\n",
    "\n",
    "\n",
    "response = oai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    stream=True,\n",
    "    messages=haiku_prompt\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a request to the OpenAI via promptsail proxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the docker and go to PromptSail UI http://localhost/\n",
    "\n",
    "\n",
    "At the application start we created test projects (project1) with OpenAI API deployment. We will use project1 for this example.\n",
    "\n",
    "In this case we will use the default `project 1` settings:\n",
    "* with project_slug -> 'project1' \n",
    "* deployment_name -> 'openai'\n",
    "resulting in promptsail proxy url like this: \n",
    "\n",
    "**http://localhost:8000/project1/openai** -> https://api.openai.com/v1\n",
    "\n",
    "You can create your own project if you want.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The number 42 is famously known as the \"Answer to the Ultimate Question of '\n",
      " 'Life, the Universe, and Everything\" in Douglas Adams\\' book \"The '\n",
      " 'Hitchhiker\\'s Guide to the Galaxy.\"')\n"
     ]
    }
   ],
   "source": [
    "ps_api_base = \"http://localhost:8000/project1/openai\"\n",
    "\n",
    "# adress with tags \n",
    "#ps_api_base = \"http://localhost:8000/project1/openai/?tags=examples,openai_sdk,chat,user_ks&target_path=\"\n",
    "\n",
    "\n",
    "ps_client = OpenAI(base_url=ps_api_base, api_key=openai_key, max_retries=0)\n",
    "\n",
    "\n",
    "model_name = \"gpt-4-turbo-preview\"\n",
    "model_name = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "response = ps_client.chat.completions.create(\n",
    "    model=model_name,\n",
    "    temperature=0.5,\n",
    "    messages=yoda_prompt,\n",
    ")\n",
    "\n",
    "pprint(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In\n",
      " loops\n",
      " of\n",
      " the\n",
      " code\n",
      ",\n",
      "\n",
      "Through\n",
      " layers\n",
      " of\n",
      " calls\n",
      " deep\n",
      ",\n",
      "\n",
      "Rec\n",
      "ursion\n",
      " whispers\n",
      ".\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "response = ps_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    stream=True,\n",
    "    messages=haiku_prompt\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-sail-hDSOLtZB-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
