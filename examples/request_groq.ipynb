{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# How to request to Groq using PromptSail proxy\n",
    "\n",
    "1. Add you API key into ```.env``` file as ```GROQ_API_KEY```, you can generate it [here](https://console.groq.com/keys)\n",
    "2. Add Groq provider to your PromptSail project. Provider structure should look like this one:\n",
    "```json\n",
    "    {\n",
    "        deployment_name: 'Groq',\n",
    "        slug: 'groq',\n",
    "        api_base: 'https://api.groq.com',\n",
    "        description: '',\n",
    "        provider_name: 'Groq'\n",
    "    }\n",
    "```\n",
    "3. Now you can send your request to ```http://localhost:8000/models-playground/groq/openai/v1/chat/completions``` where ```models-playground``` is your project's slug and ```groq``` is the provider's slug and the rest of url is a specific target path necessary for the query to work."
   ],
   "id": "d451cde1277ecc3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-02T09:06:52.656152Z",
     "start_time": "2024-07-02T09:06:49.695994Z"
    }
   },
   "source": [
    "import requests\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "api_key = config[\"GROQ_API_KEY\"]\n",
    "\n",
    "endpoint = 'http://localhost:8000/models-playground/groq'\n",
    "target_path = '/openai/v1/chat/completions'\n",
    "\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {api_key}',\n",
    "    'Content-Type': 'application/json',\n",
    "}\n",
    "\n",
    "data = {\n",
    "    'messages': [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of fast language models\",\n",
    "        }\n",
    "    ],\n",
    "    'model': 'llama3-8b-8192'\n",
    "}\n",
    "\n",
    "response = requests.post(endpoint + target_path, headers=headers, json=data)\n",
    "if response.status_code == 200:\n",
    "    print('Success:', response.json())\n",
    "else:\n",
    "    print('Error:', response.status_code, response.text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: {'id': 'chatcmpl-2e1c871a-b7cb-47b6-ab02-9694e161b800', 'object': 'chat.completion', 'created': 1719911215, 'model': 'llama3-8b-8192', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Fast language models, also known as rapid language models or efficient language models, have gained significant importance in recent years due to their ability to process and generate human-like language quickly and efficiently. Here are some reasons why fast language models are important:\\n\\n1. **Speed and Responsiveness**: Fast language models can respond quickly to user inputs, making them ideal for applications where speed and real-time interactions are crucial, such as customer service chatbots, language translation apps, and voice assistants.\\n2. **Scalability**: As the volume of data and user interactions increases, fast language models can accommodate this growth by processing larger amounts of data and generating responses at scale, making them suitable for large-scale applications.\\n3. **Efficient Use of Resources**: Fast language models are designed to be computationally efficient, using less memory and processing power while maintaining accuracy, which is essential for resource-constrained devices and environments, such as mobile devices, embedded systems, and IoT devices.\\n4. **Improved User Experience**: By providing fast and accurate language processing, fast language models enhance the user experience, reducing waiting times and increasing the overall satisfaction with language-based applications.\\n5. **Enable Real-time Conversations**: Fast language models enable real-time conversations, allowing for more natural and engaging interactions, such as language translation during phone calls, live chat support, and interactive storytelling.\\n6. **Advancements in AI**: Fast language models can accelerate the development of artificial intelligence (AI) applications, such as natural language processing (NLP), machine learning, and robotics, by providing high-quality, real-time language processing capabilities.\\n7. **Multitasking and Multilingual Support**: Fast language models can support multitasking and multilingualism, allowing users to interact with applications in multiple languages simultaneously, and enabling applications to process multiple languages at once.\\n8. **Healthcare and Education**: Fast language models can be used in healthcare and education applications to provide instant language translation for patients and students, improving communication and access to services.\\n9. **Business and Commerce**: Fast language models can enhance business operations, such as customer service, sales, and marketing, by providing instant language translation and processing, enabling global communication and commerce.\\n10. **Research and Development**: Fast language models can accelerate research in NLP, linguistics, and cognitive science, enabling scientists to analyze and understand language patterns, syntax, and semantics more effectively.\\n\\nIn summary, fast language models play a crucial role in making language-based applications faster, more efficient, and more responsive, enabling a wide range of applications and use cases, from customer service to healthcare and education.'}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 18, 'prompt_time': 0.003407116, 'completion_tokens': 520, 'completion_time': 0.420006168, 'total_tokens': 538, 'total_time': 0.423413284}, 'system_fingerprint': 'fp_c4a72fb330', 'x_groq': {'id': 'req_01j1sb4vxhfptbckpj934mf5e7'}}\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
