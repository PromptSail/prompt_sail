{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cceb27b0ca026062",
   "metadata": {},
   "source": [
    "# How to store transactions for Anthropic chat in PromptSail\n",
    "\n",
    "This guide illustrates how to store transactions for Anthropic Claude models using the [Langchain Python SDK](https://python.langchain.com/docs/integrations/chat/anthropic/). It directly interfaces with the Anthropic API Claude 3 family models.\n",
    "\n",
    "To begin, you'll need an account on [Anthropic](https://anthropic.com/). If you don't have one, create it. \n",
    "\n",
    "Next, obtain your API key ðŸ”‘ from the [Anthropic console](https://console.anthropic.com/settings/keys).\n",
    "\n",
    "Then, paste this API key into the `.env` file located in the `examples` folder and assign it to the `ANTHROPIC_API_KEY` variable.\n",
    "\n",
    "\n",
    "Install all the necessary packages from [examples/pyproject.toml](pyproject.toml) by running the following command:\n",
    "\n",
    "```bash \n",
    "cd prompt_sail/examples\n",
    "poetry install\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T11:09:16.375316Z",
     "start_time": "2024-05-06T11:09:15.765895Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Anthropic api <span style=\"color: #808000; text-decoration-color: #808000\">key</span>=<span style=\"color: #800080; text-decoration-color: #800080\">sk</span>-ant-api03-<span style=\"color: #808000; text-decoration-color: #808000\">...</span>AAA\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Anthropic api \u001B[33mkey\u001B[0m=\u001B[35msk\u001B[0m-ant-api03-\u001B[33m...\u001B[0mAAA\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from dotenv import dotenv_values\n",
    "from rich import print  \n",
    "\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "anthropic_key = config[\"ANTHROPIC_API_KEY\"]\n",
    "print(\n",
    "    f\"Anthropic api key={anthropic_key[0:13]}...{anthropic_key[-3:]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4a606063c1f0d8",
   "metadata": {},
   "source": [
    "Models comparsion you can find at [Anthropic documentation](https://docs.anthropic.com/claude/docs/models-overview#model-comparison)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d83486e077b8b",
   "metadata": {},
   "source": [
    "## This part is just about testing if the API key is correct and you can connect straight to the Anthropic API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef00ba9677bf67fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T11:09:18.793731Z",
     "start_time": "2024-05-06T11:09:18.780204Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = (\n",
    "    \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    ")\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58b0cebe67315926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T11:09:20.357892Z",
     "start_time": "2024-05-06T11:09:20.326344Z"
    }
   },
   "outputs": [],
   "source": [
    "#the smallest model \n",
    "model_name = \"claude-3-haiku-20240307\"\n",
    "\n",
    "# # middle size model\n",
    "# model_name = \"claude-3-sonnet-20240229\"\n",
    "# # the largest model\n",
    "#model_name = \"claude-3-opus-20240229\"\n",
    "\n",
    "\n",
    "chat = ChatAnthropic(temperature=0, anthropic_api_key=anthropic_key, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24feab4cd246714a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T11:09:24.111455Z",
     "start_time": "2024-05-06T11:09:21.591028Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Ich liebe Python.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'msg_01A8iBNW5oxDKtnWY7Hu9qBE'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'claude-3-haiku-20240307'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stop_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'end_turn'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stop_sequence'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'usage'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-6b0bb04c-5717-4876-91ff-37edaeaf4cc3-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1;35mAIMessage\u001B[0m\u001B[1m(\u001B[0m\n",
       "    \u001B[33mcontent\u001B[0m=\u001B[32m'Ich liebe Python.'\u001B[0m,\n",
       "    \u001B[33mresponse_metadata\u001B[0m=\u001B[1m{\u001B[0m\n",
       "        \u001B[32m'id'\u001B[0m: \u001B[32m'msg_01A8iBNW5oxDKtnWY7Hu9qBE'\u001B[0m,\n",
       "        \u001B[32m'model'\u001B[0m: \u001B[32m'claude-3-haiku-20240307'\u001B[0m,\n",
       "        \u001B[32m'stop_reason'\u001B[0m: \u001B[32m'end_turn'\u001B[0m,\n",
       "        \u001B[32m'stop_sequence'\u001B[0m: \u001B[3;35mNone\u001B[0m,\n",
       "        \u001B[32m'usage'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'input_tokens'\u001B[0m: \u001B[1;36m22\u001B[0m, \u001B[32m'output_tokens'\u001B[0m: \u001B[1;36m8\u001B[0m\u001B[1m}\u001B[0m\n",
       "    \u001B[1m}\u001B[0m,\n",
       "    \u001B[33mid\u001B[0m=\u001B[32m'run-6b0bb04c-5717-4876-91ff-37edaeaf4cc3-0'\u001B[0m\n",
       "\u001B[1m)\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chain = prompt | chat\n",
    "resp = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"text\": \"I love Python\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55210f5186f0b712",
   "metadata": {},
   "source": [
    "## Create a request to the Anthropic API via PromptSail proxy\n",
    "\n",
    "\n",
    "\n",
    "* Go to demo [PromptSail](https://try-promptsail.azurewebsites.net/) and create a new project or use an existing one.\n",
    "* [Run the PromptSail docker images](https://promptsail.com/docs/quick-start-guide/#pull-and-run-the-docker-images-from-ghcr) and go to UI at http://localhost/.\n",
    "We will have to setup a project and add ai provider. \n",
    "\n",
    "\n",
    "Create new project with you `project_slug`or edit existing one for purpose of this example we will use `model-playground`.\n",
    "\n",
    "Add your own Anthropic provider by editing the project settings and click \"Add AI Provider\" button, this will create the mapping between the Anthropic endpoint to promptsail proxy URL. \n",
    "\n",
    "In the form set the `api base url` to your Anthropic endpoint to: **'https://api.anthropic.com/v1'**\n",
    " \n",
    "and add meaningfull `deployment name`.\n",
    "\n",
    "Save the changes by clicking \"Add\" and \"Update\" button.\n",
    " \n",
    "In mongo it will create new entry in `ai_providers` array, similar to this one:\n",
    "\n",
    "```bash\n",
    "{\n",
    "     ai_providers: [\n",
    "        {\n",
    "            deployment_name: 'anth claude'\n",
    "            slug: 'anth-claude',\n",
    "            api_base: 'https://api.anthropic.com/v1',\n",
    "            description: '',\n",
    "            provider_name: 'Anthropic'\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "```\n",
    "\n",
    "In this case we will use the default `model-playground` settings:\n",
    "* with project_slug -> 'model-playground' \n",
    "* slugified deployment_name -> 'anth-claude'\n",
    "\n",
    "resulting in promptsail proxy url like this: \n",
    "\n",
    "**http://localhost:8000/model-playground/anth-claude/** or\n",
    "\n",
    "**https://try-promptsail.azurewebsites.net/api/models-playground/anth-claude/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4689486af8913431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T11:11:31.639856Z",
     "start_time": "2024-05-06T11:11:31.610813Z"
    }
   },
   "outputs": [],
   "source": [
    "ps_api_base = \"https://try-promptsail.azurewebsites.net/api/models-playground/anth-claude/\"\n",
    "\n",
    "ps_api_base = \"https://try-promptsail.azurewebsites.net/api/models-playground/anth-claude/?tags=media,copy&target_path=\"\n",
    "\n",
    "\n",
    "#the smallest model \n",
    "model_name = \"claude-3-haiku-20240307\"\n",
    "\n",
    "# # middle size model\n",
    "# model_name = \"claude-3-sonnet-20240229\"\n",
    "# # the largest model\n",
    "#model_name = \"claude-3-opus-20240229\"\n",
    "\n",
    "ps_chat = ChatAnthropic(\n",
    "    temperature=0, \n",
    "    anthropic_api_key=anthropic_key, \n",
    "    model_name=model_name,\n",
    "    anthropic_api_url=ps_api_base\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93d1cd5572f681fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T11:11:37.215076Z",
     "start_time": "2024-05-06T11:11:32.315070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Ich liebe maschinelles Lernen.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'msg_01HspHkLWqKZ3SdvYFPcCZ4k'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'claude-3-haiku-20240307'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stop_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'end_turn'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stop_sequence'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'usage'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-7ebde564-bc80-4765-95cd-47b8ef8f7c9c-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1;35mAIMessage\u001B[0m\u001B[1m(\u001B[0m\n",
       "    \u001B[33mcontent\u001B[0m=\u001B[32m'Ich liebe maschinelles Lernen.'\u001B[0m,\n",
       "    \u001B[33mresponse_metadata\u001B[0m=\u001B[1m{\u001B[0m\n",
       "        \u001B[32m'id'\u001B[0m: \u001B[32m'msg_01HspHkLWqKZ3SdvYFPcCZ4k'\u001B[0m,\n",
       "        \u001B[32m'model'\u001B[0m: \u001B[32m'claude-3-haiku-20240307'\u001B[0m,\n",
       "        \u001B[32m'stop_reason'\u001B[0m: \u001B[32m'end_turn'\u001B[0m,\n",
       "        \u001B[32m'stop_sequence'\u001B[0m: \u001B[3;35mNone\u001B[0m,\n",
       "        \u001B[32m'usage'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'input_tokens'\u001B[0m: \u001B[1;36m23\u001B[0m, \u001B[32m'output_tokens'\u001B[0m: \u001B[1;36m13\u001B[0m\u001B[1m}\u001B[0m\n",
       "    \u001B[1m}\u001B[0m,\n",
       "    \u001B[33mid\u001B[0m=\u001B[32m'run-7ebde564-bc80-4765-95cd-47b8ef8f7c9c-0'\u001B[0m\n",
       "\u001B[1m)\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps_chain = prompt | ps_chat\n",
    "resp = ps_chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"text\": \"I love Machine learning\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(resp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
