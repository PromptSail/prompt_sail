{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cceb27b0ca026062",
   "metadata": {},
   "source": [
    "# How to store transactions for Anthropic chat in PromptSail\n",
    "\n",
    "This guide illustrates how to store transactions for Anthropic Claude models using the [Langchain Python SDK](https://python.langchain.com/docs/integrations/chat/anthropic/). It directly interfaces with the Anthropic API Claude 3 family models.\n",
    "\n",
    "To begin, you'll need an account on [Anthropic](https://anthropic.com/). If you don't have one, create it. \n",
    "\n",
    "Next, obtain your API key ðŸ”‘ from the [Anthropic console](https://console.anthropic.com/settings/keys).\n",
    "\n",
    "Then, paste this API key into the `.env` file located in the `examples` folder and assign it to the `ANTHROPIC_API_KEY` variable.\n",
    "\n",
    "\n",
    "Install all the necessary packages from [examples/pyproject.toml](pyproject.toml) by running the following command:\n",
    "\n",
    "```bash \n",
    "cd prompt_sail/examples\n",
    "poetry install\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T09:52:43.666509Z",
     "start_time": "2024-07-11T09:52:42.397837Z"
    }
   },
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from dotenv import dotenv_values\n",
    "from rich import print  \n",
    "\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "anthropic_key = config[\"ANTHROPIC_API_KEY\"]\n",
    "print(\n",
    "    f\"Anthropic api key={anthropic_key[0:13]}...{anthropic_key[-3:]}\"\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anthropic api \u001B[33mkey\u001B[0m=\u001B[35msk\u001B[0m-ant-api03-\u001B[33m...\u001B[0mgAA\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Anthropic api <span style=\"color: #808000; text-decoration-color: #808000\">key</span>=<span style=\"color: #800080; text-decoration-color: #800080\">sk</span>-ant-api03-<span style=\"color: #808000; text-decoration-color: #808000\">...</span>gAA\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "5b4a606063c1f0d8",
   "metadata": {},
   "source": [
    "Models comparsion you can find at [Anthropic documentation](https://docs.anthropic.com/claude/docs/models-overview#model-comparison)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51d83486e077b8b",
   "metadata": {},
   "source": [
    "## This part is just about testing if the API key is correct and you can connect straight to the Anthropic API"
   ]
  },
  {
   "cell_type": "code",
   "id": "ef00ba9677bf67fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:52:55.558687Z",
     "start_time": "2024-07-11T09:52:55.541254Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system = (\n",
    "    \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    ")\n",
    "human = \"{text}\"\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", system), (\"human\", human)])"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "58b0cebe67315926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:52:56.496643Z",
     "start_time": "2024-07-11T09:52:56.426821Z"
    }
   },
   "source": [
    "#the smallest model \n",
    "model_name = \"claude-3-haiku-20240307\"\n",
    "\n",
    "# # middle size model\n",
    "# model_name = \"claude-3-sonnet-20240229\"\n",
    "# # the largest model\n",
    "#model_name = \"claude-3-opus-20240229\"\n",
    "\n",
    "\n",
    "chat = ChatAnthropic(temperature=0, anthropic_api_key=anthropic_key, model_name=model_name)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "24feab4cd246714a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:52:59.627957Z",
     "start_time": "2024-07-11T09:52:58.461643Z"
    }
   },
   "source": [
    "chain = prompt | chat\n",
    "resp = chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"text\": \"I love Python\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(resp)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1;35mAIMessage\u001B[0m\u001B[1m(\u001B[0m\n",
       "    \u001B[33mcontent\u001B[0m=\u001B[32m'Ich liebe Python.'\u001B[0m,\n",
       "    \u001B[33mresponse_metadata\u001B[0m=\u001B[1m{\u001B[0m\n",
       "        \u001B[32m'id'\u001B[0m: \u001B[32m'msg_01FCiTcnRgmNUu8kGgSmT94i'\u001B[0m,\n",
       "        \u001B[32m'model'\u001B[0m: \u001B[32m'claude-3-haiku-20240307'\u001B[0m,\n",
       "        \u001B[32m'stop_reason'\u001B[0m: \u001B[32m'end_turn'\u001B[0m,\n",
       "        \u001B[32m'stop_sequence'\u001B[0m: \u001B[3;35mNone\u001B[0m,\n",
       "        \u001B[32m'usage'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'input_tokens'\u001B[0m: \u001B[1;36m22\u001B[0m, \u001B[32m'output_tokens'\u001B[0m: \u001B[1;36m8\u001B[0m\u001B[1m}\u001B[0m\n",
       "    \u001B[1m}\u001B[0m,\n",
       "    \u001B[33mid\u001B[0m=\u001B[32m'run-e1a75d9a-08bf-4437-b6dd-f74c5f030772-0'\u001B[0m\n",
       "\u001B[1m)\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Ich liebe Python.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'msg_01FCiTcnRgmNUu8kGgSmT94i'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'claude-3-haiku-20240307'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stop_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'end_turn'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stop_sequence'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'usage'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-e1a75d9a-08bf-4437-b6dd-f74c5f030772-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "55210f5186f0b712",
   "metadata": {},
   "source": [
    "## Create a request to the Anthropic API via PromptSail proxy\n",
    "\n",
    "\n",
    "\n",
    "* Go to demo [PromptSail](https://try-promptsail.azurewebsites.net/) and create a new project or use an existing one.\n",
    "* [Run the PromptSail docker images](https://promptsail.com/docs/quick-start-guide/#pull-and-run-the-docker-images-from-ghcr) and go to UI at http://localhost/.\n",
    "We will have to setup a project and add ai provider. \n",
    "\n",
    "\n",
    "Create new project with you `project_slug`or edit existing one for purpose of this example we will use `model-playground`.\n",
    "\n",
    "Add your own Anthropic provider by editing the project settings and click \"Add AI Provider\" button, this will create the mapping between the Anthropic endpoint to promptsail proxy URL. \n",
    "\n",
    "In the form set the `api base url` to your Anthropic endpoint to: **'https://api.anthropic.com/v1'**\n",
    " \n",
    "and add meaningfull `deployment name`.\n",
    "\n",
    "Save the changes by clicking \"Add\" and \"Update\" button.\n",
    " \n",
    "In mongo it will create new entry in `ai_providers` array, similar to this one:\n",
    "\n",
    "```bash\n",
    "{\n",
    "     ai_providers: [\n",
    "        {\n",
    "            deployment_name: 'anth claude'\n",
    "            slug: 'anth-claude',\n",
    "            api_base: 'https://api.anthropic.com/',\n",
    "            description: '',\n",
    "            provider_name: 'Anthropic'\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "```\n",
    "\n",
    "In this case we will use the default `model-playground` settings:\n",
    "* with project_slug -> 'model-playground' \n",
    "* slugified deployment_name -> 'anth-claude'\n",
    "\n",
    "resulting in promptsail proxy url like this: \n",
    "\n",
    "**http://localhost:8000/models-playground/anth-claude/** or\n",
    "\n",
    "**https://try-promptsail.azurewebsites.net/api/models-playground/anth-claude/**"
   ]
  },
  {
   "cell_type": "code",
   "id": "4689486af8913431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:54:25.416213Z",
     "start_time": "2024-07-11T09:54:25.371873Z"
    }
   },
   "source": [
    "ps_api_base = \"http://localhost:8000/models-playground/anth-claude/\"\n",
    "ps_api_base_try = \"https://try-promptsail.azurewebsites.net/api/models-playground/anth-claude/\"\n",
    "ps_api_base_try_tagged = \"https://try-promptsail.azurewebsites.net/api/models-playground/anth-claude/?tags=media,copy&target_path=\"\n",
    "\n",
    "\n",
    "#the smallest model \n",
    "model_name = \"claude-3-haiku-20240307\"\n",
    "\n",
    "# # middle size model\n",
    "# model_name = \"claude-3-sonnet-20240229\"\n",
    "# # the largest model\n",
    "#model_name = \"claude-3-opus-20240229\"\n",
    "\n",
    "ps_chat = ChatAnthropic(\n",
    "    temperature=0, \n",
    "    anthropic_api_key=anthropic_key, \n",
    "    model_name=model_name,\n",
    "    anthropic_api_url=ps_api_base\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "93d1cd5572f681fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:54:32.840092Z",
     "start_time": "2024-07-11T09:54:29.257877Z"
    }
   },
   "source": [
    "ps_chain = prompt | ps_chat\n",
    "resp = ps_chain.invoke(\n",
    "    {\n",
    "        \"input_language\": \"English\",\n",
    "        \"output_language\": \"German\",\n",
    "        \"text\": \"I love Machine learning\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(resp)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1;35mAIMessage\u001B[0m\u001B[1m(\u001B[0m\n",
       "    \u001B[33mcontent\u001B[0m=\u001B[32m'Ich liebe maschinelles Lernen.'\u001B[0m,\n",
       "    \u001B[33mresponse_metadata\u001B[0m=\u001B[1m{\u001B[0m\n",
       "        \u001B[32m'id'\u001B[0m: \u001B[32m'msg_01FcAPW39ZUUQSmDh5hfbPaz'\u001B[0m,\n",
       "        \u001B[32m'model'\u001B[0m: \u001B[32m'claude-3-haiku-20240307'\u001B[0m,\n",
       "        \u001B[32m'stop_reason'\u001B[0m: \u001B[32m'end_turn'\u001B[0m,\n",
       "        \u001B[32m'stop_sequence'\u001B[0m: \u001B[3;35mNone\u001B[0m,\n",
       "        \u001B[32m'usage'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'input_tokens'\u001B[0m: \u001B[1;36m23\u001B[0m, \u001B[32m'output_tokens'\u001B[0m: \u001B[1;36m13\u001B[0m\u001B[1m}\u001B[0m\n",
       "    \u001B[1m}\u001B[0m,\n",
       "    \u001B[33mid\u001B[0m=\u001B[32m'run-328aa29e-05b4-4006-abf1-c0d759a8485e-0'\u001B[0m\n",
       "\u001B[1m)\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Ich liebe maschinelles Lernen.'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'id'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'msg_01FcAPW39ZUUQSmDh5hfbPaz'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'claude-3-haiku-20240307'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stop_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'end_turn'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'stop_sequence'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'usage'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-328aa29e-05b4-4006-abf1-c0d759a8485e-0'</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "437665c0b16db140"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
