{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to connect to Azure OpenAI service via PromptSail and Langchain SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First you need to get or create an Azure OpenAI resource. \n",
    "You can do it here: https://portal.azure.com/#view/Microsoft_Azure_ProjectOxford/CognitiveServicesHub/~/OpenAI\n",
    "\n",
    "Click on the chosen resource and than the \"Develop\" button in the middle of the screen.\n",
    "\n",
    "Copy the API key and endpoint and paste it into `.env` file in the `examples` folder. \n",
    "\n",
    "Install all the necessary packages from [examples/pyproject.toml](pyproject.toml) by running the following command:\n",
    "\n",
    "```bash \n",
    "cd prompt_sail/examples\n",
    "poetry install\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the connection without PromptSail\n",
    "\n",
    "Import the OpenAI Python SDK and load your API key from the environment."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T10:09:23.987416Z",
     "start_time": "2024-07-11T10:09:23.772359Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "from rich import print  \n",
    "\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "\n",
    "azure_oai_key = config[\"AZURE_OPENAI_API_KEY\"]\n",
    "api_base_url = config[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "\n",
    "deployment_name = config[\"AZURE_LLM_DEPLOYMENT_NAME\"]\n",
    "api_version = config[\"AZURE_OPENAI_API_VERSION\"]\n",
    "\n",
    "print(\n",
    "    f\"Azure OpenAI api key={azure_oai_key[0:3]}...{azure_oai_key[-5:]}\"\n",
    ")\n",
    "print(\n",
    "    f\"Azure OpenAI api endpoint={api_base_url[0:17]}...\"\n",
    ")\n",
    "print(f\"Azure OpenAI deployment name={deployment_name[0:7]}...\")\n",
    "print(f\"Azure OpenAI api version={api_version}\")"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Azure OpenAI api \u001B[33mkey\u001B[0m=\u001B[35m9b2\u001B[0m\u001B[33m...\u001B[0md67b3\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Azure OpenAI api <span style=\"color: #808000; text-decoration-color: #808000\">key</span>=<span style=\"color: #800080; text-decoration-color: #800080\">9b2</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>d67b3\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Azure OpenAI api \u001B[33mendpoint\u001B[0m=\u001B[4;94mhttps\u001B[0m\u001B[4;94m://openai-pr...\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Azure OpenAI api <span style=\"color: #808000; text-decoration-color: #808000\">endpoint</span>=<span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://openai-pr...</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Azure OpenAI deployment \u001B[33mname\u001B[0m=\u001B[35mgpt\u001B[0m-35T\u001B[33m...\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Azure OpenAI deployment <span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #800080; text-decoration-color: #800080\">gpt</span>-35T<span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Azure OpenAI api \u001B[33mversion\u001B[0m=\u001B[1;36m2023\u001B[0m-\u001B[1;36m07\u001B[0m-\u001B[1;36m01\u001B[0m-preview\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Azure OpenAI api <span style=\"color: #808000; text-decoration-color: #808000\">version</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2023</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">07</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span>-preview\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the direct connection to Azure OpenAI and Langchain SDK.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T10:10:35.402908Z",
     "start_time": "2024-07-11T10:10:32.251256Z"
    }
   },
   "source": [
    "from langchain_openai  import AzureChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ChatMessage\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
    "\n",
    "\n",
    "message = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that help rewirte an jira ticket.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Give meaningful title to this bug, RuntimeError: CUDA out of memory. Tried to allocate X MiB (GPU X; X GiB total capacity; X GiB already allocated; X MiB free; X cached)\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "message_followup = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a helpful assistant that help rewirte an jira ticket.\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"Give meaningful title to this bug, RuntimeError: CUDA out of memory. Tried to allocate X MiB (GPU X; X GiB total capacity; X GiB already allocated; X MiB free; X cached)\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        content=\"RuntimeError: CUDA out of memory. Tried to allocate X MiB (GPU X; X GiB total capacity; X GiB already allocated; X MiB free; X cached)\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content=\"The error message is too technical, could you make it more user friendly and poetic?\"\n",
    "    ),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T10:10:36.186680Z",
     "start_time": "2024-07-11T10:10:36.077409Z"
    }
   },
   "source": [
    "chat = AzureChatOpenAI(\n",
    "    openai_api_key=azure_oai_key,\n",
    "    deployment_name=deployment_name,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=api_base_url,\n",
    "    #base_url=api_base_url,\n",
    "    #model=deployment_name,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T10:10:40.213910Z",
     "start_time": "2024-07-11T10:10:38.656232Z"
    }
   },
   "source": [
    "resp = chat.invoke(message)\n",
    "print(resp) "
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1;35mAIMessage\u001B[0m\u001B[1m(\u001B[0m\n",
       "    \u001B[33mcontent\u001B[0m=\u001B[32m'Bug: RuntimeError: CUDA out of memory while allocating X MiB \u001B[0m\u001B[32m(\u001B[0m\u001B[32mGPU X; X GiB total capacity; X GiB \u001B[0m\n",
       "\u001B[32malready allocated; X MiB free; X cached\u001B[0m\u001B[32m)\u001B[0m\u001B[32m'\u001B[0m,\n",
       "    \u001B[33mresponse_metadata\u001B[0m=\u001B[1m{\u001B[0m\n",
       "        \u001B[32m'token_usage'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'completion_tokens'\u001B[0m: \u001B[1;36m37\u001B[0m, \u001B[32m'prompt_tokens'\u001B[0m: \u001B[1;36m70\u001B[0m, \u001B[32m'total_tokens'\u001B[0m: \u001B[1;36m107\u001B[0m\u001B[1m}\u001B[0m,\n",
       "        \u001B[32m'model_name'\u001B[0m: \u001B[32m'gpt-35-turbo'\u001B[0m,\n",
       "        \u001B[32m'system_fingerprint'\u001B[0m: \u001B[3;35mNone\u001B[0m,\n",
       "        \u001B[32m'prompt_filter_results'\u001B[0m: \u001B[1m[\u001B[0m\n",
       "            \u001B[1m{\u001B[0m\n",
       "                \u001B[32m'prompt_index'\u001B[0m: \u001B[1;36m0\u001B[0m,\n",
       "                \u001B[32m'content_filter_results'\u001B[0m: \u001B[1m{\u001B[0m\n",
       "                    \u001B[32m'hate'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'filtered'\u001B[0m: \u001B[3;91mFalse\u001B[0m, \u001B[32m'severity'\u001B[0m: \u001B[32m'safe'\u001B[0m\u001B[1m}\u001B[0m,\n",
       "                    \u001B[32m'self_harm'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'filtered'\u001B[0m: \u001B[3;91mFalse\u001B[0m, \u001B[32m'severity'\u001B[0m: \u001B[32m'safe'\u001B[0m\u001B[1m}\u001B[0m,\n",
       "                    \u001B[32m'sexual'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'filtered'\u001B[0m: \u001B[3;91mFalse\u001B[0m, \u001B[32m'severity'\u001B[0m: \u001B[32m'safe'\u001B[0m\u001B[1m}\u001B[0m,\n",
       "                    \u001B[32m'violence'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'filtered'\u001B[0m: \u001B[3;91mFalse\u001B[0m, \u001B[32m'severity'\u001B[0m: \u001B[32m'safe'\u001B[0m\u001B[1m}\u001B[0m\n",
       "                \u001B[1m}\u001B[0m\n",
       "            \u001B[1m}\u001B[0m\n",
       "        \u001B[1m]\u001B[0m,\n",
       "        \u001B[32m'finish_reason'\u001B[0m: \u001B[32m'stop'\u001B[0m,\n",
       "        \u001B[32m'logprobs'\u001B[0m: \u001B[3;35mNone\u001B[0m,\n",
       "        \u001B[32m'content_filter_results'\u001B[0m: \u001B[1m{\u001B[0m\n",
       "            \u001B[32m'hate'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'filtered'\u001B[0m: \u001B[3;91mFalse\u001B[0m, \u001B[32m'severity'\u001B[0m: \u001B[32m'safe'\u001B[0m\u001B[1m}\u001B[0m,\n",
       "            \u001B[32m'self_harm'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'filtered'\u001B[0m: \u001B[3;91mFalse\u001B[0m, \u001B[32m'severity'\u001B[0m: \u001B[32m'safe'\u001B[0m\u001B[1m}\u001B[0m,\n",
       "            \u001B[32m'sexual'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'filtered'\u001B[0m: \u001B[3;91mFalse\u001B[0m, \u001B[32m'severity'\u001B[0m: \u001B[32m'safe'\u001B[0m\u001B[1m}\u001B[0m,\n",
       "            \u001B[32m'violence'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'filtered'\u001B[0m: \u001B[3;91mFalse\u001B[0m, \u001B[32m'severity'\u001B[0m: \u001B[32m'safe'\u001B[0m\u001B[1m}\u001B[0m\n",
       "        \u001B[1m}\u001B[0m\n",
       "    \u001B[1m}\u001B[0m,\n",
       "    \u001B[33mid\u001B[0m=\u001B[32m'run-05f04842-cf2d-44ad-a2a2-0f8d70acb398-0'\u001B[0m,\n",
       "    \u001B[33musage_metadata\u001B[0m=\u001B[1m{\u001B[0m\u001B[32m'input_tokens'\u001B[0m: \u001B[1;36m70\u001B[0m, \u001B[32m'output_tokens'\u001B[0m: \u001B[1;36m37\u001B[0m, \u001B[32m'total_tokens'\u001B[0m: \u001B[1;36m107\u001B[0m\u001B[1m}\u001B[0m\n",
       "\u001B[1m)\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Bug: RuntimeError: CUDA out of memory while allocating X MiB (GPU X; X GiB total capacity; X GiB </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">already allocated; X MiB free; X cached)'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span><span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-35-turbo'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_filter_results'</span>: <span style=\"font-weight: bold\">[</span>\n",
       "            <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_index'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'content_filter_results'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'hate'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'self_harm'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'sexual'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "                    <span style=\"color: #008000; text-decoration-color: #008000\">'violence'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>\n",
       "                <span style=\"font-weight: bold\">}</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'content_filter_results'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'hate'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'self_harm'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'sexual'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'violence'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'filtered'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'severity'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'safe'</span><span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run-05f04842-cf2d-44ad-a2a2-0f8d70acb398-0'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">70</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">107</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a request to the AzureOpenAI via PromptSail proxy\n",
    "\n",
    "\n",
    "* Go to demo [Try PromptSail](https://try-promptsail.azurewebsites.net/) and create a new project or use an existing one.\n",
    "* [Run the PromptSail docker images](https://promptsail.com/docs/quick-start-guide/#pull-and-run-the-docker-images-from-ghcr) and go to UI at http://localhost/.\n",
    "We will have to setup a project and add ai provider. \n",
    "\n",
    "Create new project with you `project_slug`or edit existing one.\n",
    "\n",
    "Add your own Azure OpenAI provider by editing the project settings, this will map the Azure OpenAI endpoint to new proxy prompt sail URL. \n",
    "\n",
    "Set the `api base url` to your Azure OpenAI endpoint like\n",
    " \n",
    "'https://**azure_openai_resource**.openai.azure.com/'\n",
    " \n",
    " and add meaningfull `deployment name`.\n",
    "\n",
    "\n",
    "In mongo it will create new entry in `ai_providers` array, similar to this one\n",
    "\n",
    "```bash\n",
    "{\n",
    "     ai_providers: [\n",
    "        {\n",
    "            deployment_name: 'azure US deployment',\n",
    "            slug: 'azure-us-deployment',\n",
    "            api_base: 'https://[azure_openai_resource].openai.azure.com/',\n",
    "            description: '',\n",
    "            provider_name: 'Azure OpenAI'\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "```\n",
    "\n",
    "In this case we will use the default `Client campaign` settings:\n",
    "* with project_slug -> 'client-campaign' \n",
    "* deployment_name -> 'azure-us-deployment'\n",
    "resulting in promptsail proxy url like this: \n",
    "\n",
    "**\"http://localhost:8000/client-campaign/azure-us-deployment/\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "source": [
    "ps_api_base = \"http://localhost:8000/client-campaign/azure-prompt-sail-eus2/\"\n",
    "\n",
    "chat = AzureChatOpenAI(\n",
    "    openai_api_key=azure_oai_key,\n",
    "    deployment_name=deployment_name,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=ps_api_base,\n",
    "\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "resp = chat.invoke(message)\n",
    "print(resp)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure OpenAI costs calculation and model versions\n",
    "\n",
    "\n",
    "The Azure OpenAI responses do not include the version of the model used to generate the response, request contains the `deployment_name` and response returns just model famili eg, `gpt-3.5-turbo` and not `gpt-3.5-turbo-1106`, this makes impossible to track and calculate costs accurately. To address this issue, you can pass the model_version parameter to the AzureChatOpenAI class, which will append the version to the model name in the output. This allows for easy differentiation between different versions of the model.\n",
    "\n",
    "\n",
    "Ensure that your deployment supports the chosen model version, as different regions support various models and versions. You can verify the supported models and versions in each region by following this\n",
    "[Azure OpenAI Model summary table and region availability](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#model-summary-table-and-region-availability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "source": [
    "ps_api_base_model_version_tag = \"http://localhost:8000/client-campaign/azure-prompt-sail-eus2/?tags=examples,langchain-v0.0.354&target_path=\"\n",
    "\n",
    "#ps_api_base_model_version_tag = \"https://try-promptsail.azurewebsites.net/api/models-playground/azure-eastus/?ai_model_version=gpt-4o-2024-05-13&target_path=\"\n",
    "\n",
    "chat_0613 = AzureChatOpenAI(\n",
    "    openai_api_key=azure_oai_key,\n",
    "    deployment_name=deployment_name,\n",
    "    api_version=api_version,\n",
    "    azure_endpoint=ps_api_base_model_version_tag,\n",
    "    #model_version=\"0613\",\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "source": [
    "chat_0613(message_followup)"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-sail-hDSOLtZB-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
