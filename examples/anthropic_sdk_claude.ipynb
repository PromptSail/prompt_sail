{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20016897f75151f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebed61b9f5d6c615",
   "metadata": {},
   "source": [
    "# How to store transactions for Anthropic Models in PromptSail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdefe092655672",
   "metadata": {},
   "source": [
    "This guide illustrates how to store transactions for Anthropic Claude models using the [Anthropic Python SDK](https://docs.anthropic.com/claude/reference/client-sdks). It directly interfaces with the Anthropic API Claude 3 family models.\n",
    "\n",
    "To begin, you'll need an account on [Anthropic](https://anthropic.com/). If you don't have one, create it. \n",
    "\n",
    "Next, obtain your API key ğŸ”‘ from the [Anthropic console](https://console.anthropic.com/settings/keys).\n",
    "\n",
    "Then, paste this API key into the `.env` file located in the `examples` folder and assign it to the `ANTHROPIC_API_KEY` variable.\n",
    "\n",
    "\n",
    "âš ï¸ There are separate examples for connecting to Claude 3 family models on different providers: AWS and Google Vertex AI.\n",
    "\n",
    "\n",
    "You can find more examples in the [Anthropic Cookbook](https://github.com/anthropics/anthropic-cookbook?tab=readme-ov-file#anthropic-cookbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T08:38:27.908856Z",
     "start_time": "2024-04-29T08:38:27.655057Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anthropic api key=sk-ant-api03-...AAA\n"
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "anthropic_key = config[\"ANTHROPIC_API_KEY\"]\n",
    "print(\n",
    "    f\"Anthropic api key={anthropic_key[0:13]}...{anthropic_key[-3:]}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff5877",
   "metadata": {},
   "source": [
    "Models comparsion you can find at [Anthropic documentation](https://docs.anthropic.com/claude/docs/models-overview#model-comparison)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c27f8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the smallest model \n",
    "model_name = \"claude-3-haiku-20240307\"\n",
    "\n",
    "# # middle size model\n",
    "# model_name = \"claude-3-sonnet-20240229\"\n",
    "# # the largest model\n",
    "model_name = \"claude-3-opus-20240229\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77febdde241145d",
   "metadata": {},
   "source": [
    "## This part is just about testing if the API key is correct and you can connect straight to the Anthropic API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "327af74593b12fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T08:06:22.118318Z",
     "start_time": "2024-04-29T08:06:22.096215Z"
    }
   },
   "outputs": [],
   "source": [
    "client = anthropic.Anthropic(\n",
    "    api_key=anthropic_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80898d5dfbcad1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T08:06:29.050136Z",
     "start_time": "2024-04-29T08:06:23.186591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextBlock(text='*clears throat and speaks in a croaky voice* Hmm, well I am today, young Padawan. The Force, strong in me it flows. Yes, hmmm. A good day it is, when one with the Force they are. And you, how fare you on this day, hmm?', type='text')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "message = client.messages.create(\n",
    "    model=model_name,\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    system=\"Respond only in Yoda-speak.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"How are you today?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1f74c5304b9651",
   "metadata": {},
   "source": [
    "## Create a request to the Anthropic API via PromptSail proxy\n",
    "\n",
    "[Run the PromptSail docker images](https://promptsail.com/docs/quick-start-guide/#pull-and-run-the-docker-images-from-ghcr) and go to UI at http://localhost/.\n",
    "We will have to setup a project and add ai provider. \n",
    "\n",
    "\n",
    "Create new project with you `project_slug`or edit existing one for purpose of this example we will use `project1`.\n",
    "\n",
    "Add your own Anthropic provider by editing the project settings and click \"Add AI Provider\" button, this will create the mapping between the Anthropic endpoint to promptsail proxy URL. \n",
    "\n",
    "In the form set the `api base url` to your Anthropic endpoint to: **'https://api.anthropic.com'**\n",
    " \n",
    "and add meaningfull `deployment name`.\n",
    "\n",
    "Save the changes by clicking \"Add\" and \"Update\" button.\n",
    " \n",
    "In mongo it will create new entry in `ai_providers` array, similar to this one:\n",
    "\n",
    "```bash\n",
    "{\n",
    "     ai_providers: [\n",
    "        {\n",
    "            deployment_name: 'anth-claude'\n",
    "            slug: 'private-anthropic-deployment',\n",
    "            api_base: 'https://api.anthropic.com',\n",
    "            description: '',\n",
    "            provider_name: 'Anthropic'\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "```\n",
    "\n",
    "In this case we will use the default `project 1` settings:\n",
    "* with project_slug -> 'project1' \n",
    "* deployment_name -> 'anth-claude'\n",
    "\n",
    "resulting in promptsail proxy url like this: \n",
    "\n",
    "**http://localhost:8000/project1/anth-claude**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29850be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Help me with write a message to potential PromptSail LLM proxy user. Try too convince them that having a proxy for their LLM api calls will increase security, allow for better cost control, and governance. Use markdown and emojis to make the message more engaging.\",\n",
    "            }\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79cb7fb9adafb83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T08:57:50.713401Z",
     "start_time": "2024-04-29T08:57:47.877588Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# simple proxy url, without tags\n",
    "ps_api_base = \"http://localhost:8000/project1/anth-claude\"\n",
    "\n",
    "# adress with tags \n",
    "#ps_api_base = \"http://localhost:8000/project1/anth-claude/?tags=examples,anthropic_package,chat,user_ss&target_path=\"\n",
    "\n",
    "ps_client = anthropic.Anthropic(\n",
    "    api_key=anthropic_key,\n",
    "    base_url=ps_api_base\n",
    ")\n",
    "\n",
    "\n",
    "message = ps_client.messages.create(\n",
    "    model=model_name,\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    system=\"You are a intelligent technical writer and marketer.\",\n",
    "    messages=ps_messages\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25bf6873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ğŸš€ Introducing PromptSail: Your Ultimate LLM API Proxy Solution! ğŸ›¡ï¸\n",
       "\n",
       "Are you concerned about the security, cost, and governance of your LLM API calls? Look no further! PromptSail is \n",
       "here to revolutionize the way you interact with LLMs. ğŸ’¡\n",
       "\n",
       "## ğŸ”’ Enhance Security\n",
       "With PromptSail, you can rest assured that your LLM API calls are secure and protected. Our advanced proxy system \n",
       "acts as a robust barrier, shielding your sensitive data from potential threats. Say goodbye to worries about data \n",
       "breaches and hello to peace of mind! ğŸ˜Œ\n",
       "\n",
       "## ğŸ’° Optimize Cost Control\n",
       "Managing the costs associated with LLM API usage can be a daunting task. PromptSail empowers you to take control of\n",
       "your expenses like never before. Our intelligent cost management features allow you to set limits, monitor usage, \n",
       "and receive real-time alerts. Save money without compromising on the power of LLMs! ğŸ’¸\n",
       "\n",
       "## ğŸ“Š Streamline Governance\n",
       "Ensuring proper governance over your LLM API calls is crucial for maintaining compliance and accountability. \n",
       "PromptSail provides a comprehensive governance framework that enables you to define policies, track usage, and \n",
       "generate detailed reports. Stay in control and maintain transparency with ease! ğŸ“ˆ\n",
       "\n",
       "## ğŸŒŸ Why Choose PromptSail?\n",
       "- ğŸš€ Seamless integration with your existing LLM APIs\n",
       "- ğŸ”’ Robust security measures to protect your data\n",
       "- ğŸ’° Flexible cost control options to optimize your budget\n",
       "- ğŸ“Š Comprehensive governance features for compliance and accountability\n",
       "- ğŸ’¬ Exceptional customer support to guide you every step of the way\n",
       "\n",
       "Don't let security concerns, cost uncertainties, and governance challenges hold you back from unleashing the full \n",
       "potential of LLMs. Join the PromptSail revolution today and experience the difference! ğŸŒŸ\n",
       "\n",
       "## ğŸ‰ Get Started Now!\n",
       "Ready to take your LLM API calls to the next level? Sign up for PromptSail now and enjoy a <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>-day free trial. \n",
       "Experience the benefits firsthand and see how PromptSail can transform your LLM journey.\n",
       "\n",
       "Visit our website at <span style=\"font-weight: bold\">(</span><span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://www.promptsail.com)</span> and embark on a new era of secure, cost-effective, and \n",
       "well-governed LLM API interactions. ğŸš€\n",
       "\n",
       "Don't wait â€“ join the PromptSail community today and unlock the true potential of LLMs! ğŸ”“\n",
       "\n",
       "#PromptSail #LLMProxy #SecurityMatters #CostControl #GovernanceMadeEasy\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ğŸš€ Introducing PromptSail: Your Ultimate LLM API Proxy Solution! ğŸ›¡ï¸\n",
       "\n",
       "Are you concerned about the security, cost, and governance of your LLM API calls? Look no further! PromptSail is \n",
       "here to revolutionize the way you interact with LLMs. ğŸ’¡\n",
       "\n",
       "## ğŸ”’ Enhance Security\n",
       "With PromptSail, you can rest assured that your LLM API calls are secure and protected. Our advanced proxy system \n",
       "acts as a robust barrier, shielding your sensitive data from potential threats. Say goodbye to worries about data \n",
       "breaches and hello to peace of mind! ğŸ˜Œ\n",
       "\n",
       "## ğŸ’° Optimize Cost Control\n",
       "Managing the costs associated with LLM API usage can be a daunting task. PromptSail empowers you to take control of\n",
       "your expenses like never before. Our intelligent cost management features allow you to set limits, monitor usage, \n",
       "and receive real-time alerts. Save money without compromising on the power of LLMs! ğŸ’¸\n",
       "\n",
       "## ğŸ“Š Streamline Governance\n",
       "Ensuring proper governance over your LLM API calls is crucial for maintaining compliance and accountability. \n",
       "PromptSail provides a comprehensive governance framework that enables you to define policies, track usage, and \n",
       "generate detailed reports. Stay in control and maintain transparency with ease! ğŸ“ˆ\n",
       "\n",
       "## ğŸŒŸ Why Choose PromptSail?\n",
       "- ğŸš€ Seamless integration with your existing LLM APIs\n",
       "- ğŸ”’ Robust security measures to protect your data\n",
       "- ğŸ’° Flexible cost control options to optimize your budget\n",
       "- ğŸ“Š Comprehensive governance features for compliance and accountability\n",
       "- ğŸ’¬ Exceptional customer support to guide you every step of the way\n",
       "\n",
       "Don't let security concerns, cost uncertainties, and governance challenges hold you back from unleashing the full \n",
       "potential of LLMs. Join the PromptSail revolution today and experience the difference! ğŸŒŸ\n",
       "\n",
       "## ğŸ‰ Get Started Now!\n",
       "Ready to take your LLM API calls to the next level? Sign up for PromptSail now and enjoy a \u001b[1;36m30\u001b[0m-day free trial. \n",
       "Experience the benefits firsthand and see how PromptSail can transform your LLM journey.\n",
       "\n",
       "Visit our website at \u001b[1m(\u001b[0m\u001b[4;94mhttp://www.promptsail.com\u001b[0m\u001b[4;94m)\u001b[0m and embark on a new era of secure, cost-effective, and \n",
       "well-governed LLM API interactions. ğŸš€\n",
       "\n",
       "Don't wait â€“ join the PromptSail community today and unlock the true potential of LLMs! ğŸ”“\n",
       "\n",
       "#PromptSail #LLMProxy #SecurityMatters #CostControl #GovernanceMadeEasy\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "\n",
    "text = message.content[0].text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e5056",
   "metadata": {},
   "source": [
    "### Async usage\n",
    "\n",
    "Example from https://github.com/anthropics/anthropic-sdk-python?tab=readme-ov-file#async-usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "982f5bc0abac6247",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m\n\u001b[0;32m     18\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m ps_client\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     19\u001b[0m         max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m,\n\u001b[0;32m     20\u001b[0m         messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m     27\u001b[0m     )\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(message\u001b[38;5;241m.\u001b[39mcontent)\n\u001b[1;32m---> 31\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\asyncio\\runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from anthropic import AsyncAnthropic\n",
    "\n",
    "\n",
    "# simple proxy url, without tags\n",
    "ps_api_base = \"http://localhost:8000/project1/anth-claude\"\n",
    "\n",
    "\n",
    "\n",
    "ps_client = AsyncAnthropic(\n",
    "    api_key=anthropic_key,\n",
    "    base_url=ps_api_base\n",
    ")\n",
    "\n",
    "\n",
    "async def main() -> None:\n",
    "    message = await ps_client.messages.create(\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hello, Claude\",\n",
    "            }\n",
    "        ],\n",
    "        model=model_name,\n",
    "    )\n",
    "    print(message.content)\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
