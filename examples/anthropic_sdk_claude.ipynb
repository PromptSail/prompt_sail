{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20016897f75151f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebed61b9f5d6c615",
   "metadata": {},
   "source": [
    "# How to store transactions for Anthropic Models in PromptSail"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdefe092655672",
   "metadata": {},
   "source": [
    "This guide illustrates how to store transactions for Anthropic Claude models using the [Anthropic Python SDK](https://docs.anthropic.com/claude/reference/client-sdks). It directly interfaces with the Anthropic API Claude 3 family models.\n",
    "\n",
    "To begin, you'll need an account on [Anthropic](https://anthropic.com/). If you don't have one, create it. \n",
    "\n",
    "Next, obtain your API key üîë from the [Anthropic console](https://console.anthropic.com/settings/keys).\n",
    "\n",
    "Then, paste this API key into the `.env` file located in the `examples` folder and assign it to the `ANTHROPIC_API_KEY` variable.\n",
    "\n",
    "\n",
    "‚ö†Ô∏è There are separate examples for connecting to Claude 3 family models on different providers: AWS and Google Vertex AI.\n",
    "\n",
    "\n",
    "You can find more examples in the [Anthropic Cookbook](https://github.com/anthropics/anthropic-cookbook?tab=readme-ov-file#anthropic-cookbook)"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T09:41:09.538371Z",
     "start_time": "2024-07-11T09:41:08.671267Z"
    }
   },
   "source": [
    "import anthropic\n",
    "from dotenv import dotenv_values\n",
    "from rich import print\n",
    "\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "\n",
    "anthropic_key = config[\"ANTHROPIC_API_KEY\"]\n",
    "print(\n",
    "    f\"Anthropic api key={anthropic_key[0:13]}...{anthropic_key[-3:]}\"\n",
    ")\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Anthropic api \u001B[33mkey\u001B[0m=\u001B[35msk\u001B[0m-ant-api03-\u001B[33m...\u001B[0mgAA\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Anthropic api <span style=\"color: #808000; text-decoration-color: #808000\">key</span>=<span style=\"color: #800080; text-decoration-color: #800080\">sk</span>-ant-api03-<span style=\"color: #808000; text-decoration-color: #808000\">...</span>gAA\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "edff5877",
   "metadata": {},
   "source": [
    "Models comparsion you can find at [Anthropic documentation](https://docs.anthropic.com/claude/docs/models-overview#model-comparison)."
   ]
  },
  {
   "cell_type": "code",
   "id": "c27f8a0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:41:11.795596Z",
     "start_time": "2024-07-11T09:41:11.788202Z"
    }
   },
   "source": [
    "#the smallest model \n",
    "model_name = \"claude-3-haiku-20240307\"\n",
    "\n",
    "# # middle size model\n",
    "# model_name = \"claude-3-sonnet-20240229\"\n",
    "# # the largest model\n",
    "#model_name = \"claude-3-opus-20240229\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "a77febdde241145d",
   "metadata": {},
   "source": [
    "## This part is just about testing if the API key is correct and you can connect straight to the Anthropic API"
   ]
  },
  {
   "cell_type": "code",
   "id": "327af74593b12fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:41:24.768937Z",
     "start_time": "2024-07-11T09:41:24.736808Z"
    }
   },
   "source": [
    "client = anthropic.Anthropic(\n",
    "    api_key=anthropic_key,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f80898d5dfbcad1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:41:36.363180Z",
     "start_time": "2024-07-11T09:41:34.905208Z"
    }
   },
   "source": [
    "message = client.messages.create(\n",
    "    model=model_name,\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    system=\"Respond only in Yoda-speak.\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"How are you today?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(message.content)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1m[\u001B[0m\n",
       "    \u001B[1;35mTextBlock\u001B[0m\u001B[1m(\u001B[0m\n",
       "        \u001B[33mtext\u001B[0m=\u001B[32m'Hmm, good I am, thank you for asking. Careful I will be, to avoid any copyrighted material. Summarize\u001B[0m\n",
       "\u001B[32mor quote, I can, but reproduce, I will not. Yoda-speak, I shall use, to the best of my ability.'\u001B[0m,\n",
       "        \u001B[33mtype\u001B[0m=\u001B[32m'text'\u001B[0m\n",
       "    \u001B[1m)\u001B[0m\n",
       "\u001B[1m]\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TextBlock</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">text</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'Hmm, good I am, thank you for asking. Careful I will be, to avoid any copyrighted material. Summarize</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">or quote, I can, but reproduce, I will not. Yoda-speak, I shall use, to the best of my ability.'</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>\n",
       "    <span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "3f1f74c5304b9651",
   "metadata": {},
   "source": [
    "## Create a request to the Anthropic API via PromptSail proxy\n",
    "\n",
    "\n",
    "\n",
    "* Go to demo [PromptSail](https://try-promptsail.azurewebsites.net/) and create a new project or use an existing one.\n",
    "* [Run the PromptSail docker images](https://promptsail.com/docs/quick-start-guide/#pull-and-run-the-docker-images-from-ghcr) and go to UI at http://localhost/.\n",
    "We will have to setup a project and add ai provider. \n",
    "\n",
    "\n",
    "Create new project with you `project_slug`or edit existing one for purpose of this example we will use `model-playground`.\n",
    "\n",
    "Add your own Anthropic provider by editing the project settings and click \"Add AI Provider\" button, this will create the mapping between the Anthropic endpoint to promptsail proxy URL. \n",
    "\n",
    "In the form set the `api base url` to your Anthropic endpoint to: **'https://api.anthropic.com/v1'**\n",
    " \n",
    "and add meaningfull `deployment name`.\n",
    "\n",
    "Save the changes by clicking \"Add\" and \"Update\" button.\n",
    " \n",
    "In mongo it will create new entry in `ai_providers` array, similar to this one:\n",
    "\n",
    "```bash\n",
    "{\n",
    "     ai_providers: [\n",
    "        {\n",
    "            deployment_name: 'anth claude'\n",
    "            slug: 'anth-claude',\n",
    "            api_base: 'https://api.anthropic.com/',\n",
    "            description: '',\n",
    "            provider_name: 'Anthropic'\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "```\n",
    "\n",
    "In this case we will use the default `Models playground` settings:\n",
    "* with project_slug -> 'models-playground' \n",
    "* slugified deployment_name -> 'anth-claude'\n",
    "\n",
    "resulting in promptsail proxy url like this: \n",
    "\n",
    "**http://localhost:8000/models-playground/anth-claude/** or\n",
    "\n",
    "**https://try-promptsail.azurewebsites.net/api/models-playground/anth-claude/**"
   ]
  },
  {
   "cell_type": "code",
   "id": "29850be4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:44:31.605586Z",
     "start_time": "2024-07-11T09:44:31.595338Z"
    }
   },
   "source": [
    "ps_messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Help me write a message to a potential PromptSail LLM proxy user. Try to convince them that having a proxy for their LLM API calls will increase security and allow for better cost control and governance. Use markdown and emojis to make the message more engaging.\",\n",
    "    },\n",
    "    {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"ok, please paste the snippet with main information about the product and I will help you to create a message.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Below is a list of features that PromptSail offers taken from the website. Use this information to create a message that will convince potential users try and download the dokcer image from github container registry (ghcr.io).\n",
    "Transparent Logging It captures and logs all interactions with LLM APIs, providing a comprehensive record of prompts and responses.\n",
    "\n",
    "Cost Insights Project managers can track and analyze the costs associated with each project and experiment, enabling better budget management.\n",
    "\n",
    "Optimization and Analysis By providing a concise and detailed view of all interactions, developers can analyze and refine their prompts.\n",
    "\n",
    "Compliance and Governance Empowers business owners to maintain control over instructions, chat messages, and other interactions with LLM APIs. This enables the implementation of standards and policies, identification of misuse, and detection of non-compliant content.\n",
    "\n",
    "Easy Integration Prompt Sail seamlessly integrates into your workflow and used libraries. Just modify the base_url parameter when creating your provider API object.\n",
    "\n",
    "Searchable Database All prompts and responses are stored in a MongoDB, making finding and analyzing specific interactions easy. You can export the data for further analysis.\n",
    "\n",
    "User-Friendly Interface Simple and intuitive UI lets you easily view and filter your transactions (prompts and responses) by project, API provider, LLM model, or tags \"\"\",\n",
    "    },\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15e06253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the smallest model \n",
    "model_name = \"claude-3-haiku-20240307\"\n",
    "\n",
    "# # middle size model\n",
    "# model_name = \"claude-3-sonnet-20240229\"\n",
    "# # the largest model\n",
    "#model_name = \"claude-3-opus-20240229\""
   ]
  },
  {
   "cell_type": "code",
   "id": "c79cb7fb9adafb83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:46:16.838765Z",
     "start_time": "2024-07-11T09:46:10.504146Z"
    }
   },
   "source": [
    "# simple proxy url, without tags\n",
    "ps_api_base = \"http://localhost:8000/models-playground/anth-claude/\"\n",
    "ps_api_base_try = \"https://try-promptsail.azurewebsites.net/api/models-playground/anth-claude/\"\n",
    "\n",
    "# alternative version adress with tags \n",
    "\n",
    "ps_api_base_tagged = \"http://localhost:8000/project1/anth-claude/?tags=examples,anthropic_package,chat,user_ss&target_path=\"\n",
    "ps_api_base_try_tagged = \"https://try-promptsail.azurewebsites.net/api/models-playground/anth-claude/?tags=media,copy&target_path=\"\n",
    "\n",
    "\n",
    "ps_client = anthropic.Anthropic(\n",
    "    api_key=anthropic_key,\n",
    "    base_url=ps_api_base\n",
    ")\n",
    "\n",
    "message = ps_client.messages.create(\n",
    "    model=model_name,\n",
    "    max_tokens=1000,\n",
    "    temperature=0.0,\n",
    "    system=\"You are a intelligent technical writer and marketer.\",\n",
    "    messages=ps_messages\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25bf6873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sure, here's a message that highlights the key features of PromptSail and aims to convince potential users to try \n",
       "it out:\n",
       "\n",
       "# üö¢ Sail Through Your LLM API Calls with PromptSail! üåä\n",
       "\n",
       "Are you tired of the lack of visibility and control over your Language Model API usage? üëÄ Introducing \n",
       "**PromptSail** - the ultimate proxy solution that will revolutionize the way you interact with your LLM APIs!\n",
       "\n",
       "With PromptSail, you'll enjoy a suite of powerful features that will take your LLM workflow to new heights:\n",
       "\n",
       "## üîç Transparent Logging\n",
       "PromptSail captures and logs all your interactions with LLM APIs, providing a comprehensive record of prompts and \n",
       "responses. Never lose track of your conversations again! \n",
       "\n",
       "## üí∞ Cost Insights\n",
       "Gain complete control over your LLM API spending. PromptSail allows project managers to track and analyze the costs\n",
       "associated with each project and experiment, enabling better budget management.\n",
       "\n",
       "## üîç Optimization and Analysis\n",
       "Dive deep into your prompts and responses with PromptSail's detailed view. Analyze and refine your prompts to \n",
       "achieve maximum efficiency and effectiveness.\n",
       "\n",
       "## üîí Compliance and Governance\n",
       "Empower your business with PromptSail's compliance and governance features. Maintain control over instructions, \n",
       "chat messages, and other interactions, ensuring adherence to your standards and policies.\n",
       "\n",
       "## üõ†Ô∏è Easy Integration\n",
       "Seamlessly integrate PromptSail into your existing workflow. Simply modify the base_url parameter when creating \n",
       "your provider API object, and you're good to go!\n",
       "\n",
       "## üóÑÔ∏è Searchable Database\n",
       "All your prompts and responses are stored in a MongoDB database, making it easy to find and analyze specific \n",
       "interactions. Export the data for further analysis and insights.\n",
       "\n",
       "## üß≠ User-Friendly Interface\n",
       "Navigating PromptSail is a breeze! Our simple and intuitive UI allows you to easily view and filter your \n",
       "transactions by project, API provider, LLM model, or tags.\n",
       "\n",
       "Don't let the chaos of LLM API usage hold you back. üöÄ Sail with PromptSail and take control of your LLM workflow \n",
       "today! \n",
       "\n",
       "Download the Docker image from the GitHub Container Registry <span style=\"font-weight: bold\">(</span>ghcr.io<span style=\"font-weight: bold\">)</span> and start your journey towards better \n",
       "security, cost control, and governance.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Sure, here's a message that highlights the key features of PromptSail and aims to convince potential users to try \n",
       "it out:\n",
       "\n",
       "# üö¢ Sail Through Your LLM API Calls with PromptSail! üåä\n",
       "\n",
       "Are you tired of the lack of visibility and control over your Language Model API usage? üëÄ Introducing \n",
       "**PromptSail** - the ultimate proxy solution that will revolutionize the way you interact with your LLM APIs!\n",
       "\n",
       "With PromptSail, you'll enjoy a suite of powerful features that will take your LLM workflow to new heights:\n",
       "\n",
       "## üîç Transparent Logging\n",
       "PromptSail captures and logs all your interactions with LLM APIs, providing a comprehensive record of prompts and \n",
       "responses. Never lose track of your conversations again! \n",
       "\n",
       "## üí∞ Cost Insights\n",
       "Gain complete control over your LLM API spending. PromptSail allows project managers to track and analyze the costs\n",
       "associated with each project and experiment, enabling better budget management.\n",
       "\n",
       "## üîç Optimization and Analysis\n",
       "Dive deep into your prompts and responses with PromptSail's detailed view. Analyze and refine your prompts to \n",
       "achieve maximum efficiency and effectiveness.\n",
       "\n",
       "## üîí Compliance and Governance\n",
       "Empower your business with PromptSail's compliance and governance features. Maintain control over instructions, \n",
       "chat messages, and other interactions, ensuring adherence to your standards and policies.\n",
       "\n",
       "## üõ†Ô∏è Easy Integration\n",
       "Seamlessly integrate PromptSail into your existing workflow. Simply modify the base_url parameter when creating \n",
       "your provider API object, and you're good to go!\n",
       "\n",
       "## üóÑÔ∏è Searchable Database\n",
       "All your prompts and responses are stored in a MongoDB database, making it easy to find and analyze specific \n",
       "interactions. Export the data for further analysis and insights.\n",
       "\n",
       "## üß≠ User-Friendly Interface\n",
       "Navigating PromptSail is a breeze! Our simple and intuitive UI allows you to easily view and filter your \n",
       "transactions by project, API provider, LLM model, or tags.\n",
       "\n",
       "Don't let the chaos of LLM API usage hold you back. üöÄ Sail with PromptSail and take control of your LLM workflow \n",
       "today! \n",
       "\n",
       "Download the Docker image from the GitHub Container Registry \u001B[1m(\u001B[0mghcr.io\u001B[1m)\u001B[0m and start your journey towards better \n",
       "security, cost control, and governance.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import print\n",
    "\n",
    "text = message.content[0].text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320e5056",
   "metadata": {},
   "source": [
    "### Async usage\n",
    "\n",
    "Example from https://github.com/anthropics/anthropic-sdk-python?tab=readme-ov-file#async-usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "982f5bc0abac6247",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 31\u001B[0m\n\u001B[0;32m     18\u001B[0m     message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m ps_client\u001B[38;5;241m.\u001B[39mmessages\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[0;32m     19\u001B[0m         max_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1024\u001B[39m,\n\u001B[0;32m     20\u001B[0m         messages\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     26\u001B[0m         model\u001B[38;5;241m=\u001B[39mmodel_name,\n\u001B[0;32m     27\u001B[0m     )\n\u001B[0;32m     28\u001B[0m     \u001B[38;5;28mprint\u001B[39m(message\u001B[38;5;241m.\u001B[39mcontent)\n\u001B[1;32m---> 31\u001B[0m \u001B[43masyncio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.pyenv\\pyenv-win\\versions\\3.10.6\\lib\\asyncio\\runners.py:33\u001B[0m, in \u001B[0;36mrun\u001B[1;34m(main, debug)\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \n\u001B[0;32m     11\u001B[0m \u001B[38;5;124;03mThis function runs the passed coroutine, taking care of\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03m    asyncio.run(main())\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m events\u001B[38;5;241m.\u001B[39m_get_running_loop() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 33\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m     34\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124masyncio.run() cannot be called from a running event loop\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m coroutines\u001B[38;5;241m.\u001B[39miscoroutine(main):\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma coroutine was expected, got \u001B[39m\u001B[38;5;132;01m{!r}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(main))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from anthropic import AsyncAnthropic\n",
    "\n",
    "\n",
    "# simple proxy url, without tags\n",
    "ps_api_base = \"http://localhost:8000/project1/anth-claude/\"\n",
    "\n",
    "\n",
    "ps_client = AsyncAnthropic(\n",
    "    api_key=anthropic_key,\n",
    "    base_url=ps_api_base\n",
    ")\n",
    "\n",
    "async def main() -> None:\n",
    "    message = await ps_client.messages.create(\n",
    "        max_tokens=1024,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Hello, Claude\",\n",
    "            }\n",
    "        ],\n",
    "        model=model_name,\n",
    "    )\n",
    "    print(message.content)\n",
    "\n",
    "\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
