---
title: "Deployment recipes for Prompt Sail"
permalink: /docs/deploy-promptsail-cookbook
excerpt: "How to deploy Prompt Sail on Azure, AWS, GCP, or your local machine."
last_modified_at: 2024-05-05T11:48:05+01:00
redirect_from:
  - /theme-setup/
toc: true
toc_sticky: true
---


## Deployment Cookbook


Is a self-hosted application that captures and logs all interactions with LLM APIs such as OpenAI, Anthropic, Google Gemini and others. It is a proxy between your framework of choice (LangChain, OpenAI etc) and LLM provider API. 

For **developers**, it offers a way to analyze and optimize API prompts. 

For **Project managers** can gain insights into project and experiment costs. 

For **Business owners** can ensure compliance with regulations and maintain governance over prompts and responses.


### Deployment Options

There are several ways to deploy Prompt Sail:
* [Local deployment](/docs/deploy-promptsail-local/
* [Azure deployment](/docs/deploy-promptsail-azure) (help needed #good-first-issue)
* [AWS deployment](/docs/deploy-promptsail-aws) (help needed #good-first-issue)
* [GCP deployment](/docs/deploy-promptsail-gcp) (help needed #good-first-issue)



